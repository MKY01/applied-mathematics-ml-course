{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 11 â€” Ensemble Methods (Solutions)\n",
    "\n",
    "Here are the completed solutions for Bagging, Random Forests, AdaBoost, Gradient Boosting, and Stacking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1 â€” Bagging with Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Single Decision Tree\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "tree_acc = accuracy_score(y_test, tree.predict(X_test))\n",
    "\n",
    "# Bagging Classifier (use 'estimator' for sklearn >= 1.2)\n",
    "bagging = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "bagging.fit(X_train, y_train)\n",
    "bagging_acc = accuracy_score(y_test, bagging.predict(X_test))\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {tree_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2 â€” Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.887\n",
      "Top 5 Feature Importances:\n",
      "Feature 12: 0.134\n",
      "Feature 6: 0.068\n",
      "Feature 2: 0.067\n",
      "Feature 5: 0.067\n",
      "Feature 17: 0.058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "\n",
    "print(f\"Random Forest Accuracy: {rf_acc:.3f}\")\n",
    "print(\"Top 5 Feature Importances:\")\n",
    "importances = sorted(zip(rf.feature_importances_, range(X.shape[1])), reverse=True)[:5]\n",
    "for imp, idx in importances:\n",
    "    print(f\"Feature {idx}: {imp:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3 â€” AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "adaboost.fit(X_train, y_train)\n",
    "adaboost_acc = accuracy_score(y_test, adaboost.predict(X_test))\n",
    "\n",
    "print(f\"AdaBoost Accuracy: {adaboost_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 4 â€” Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "gb_acc = accuracy_score(y_test, gb.predict(X_test))\n",
    "\n",
    "print(f\"Gradient Boosting Accuracy: {gb_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 5 â€” Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Accuracy: 0.887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimators = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=50, random_state=42))\n",
    "]\n",
    "\n",
    "stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
    "stacking.fit(X_train, y_train)\n",
    "stacking_acc = accuracy_score(y_test, stacking.predict(X_test))\n",
    "\n",
    "print(f\"Stacking Accuracy: {stacking_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”Ž Summary of Results\n",
    "- Decision Tree â†’ baseline performance\n",
    "- Bagging â†’ reduces variance, generally better than a single tree\n",
    "- Random Forest â†’ often best among bagging-based methods, adds feature randomness\n",
    "- AdaBoost â†’ sequentially focuses on hard examples, strong learner\n",
    "- Gradient Boosting â†’ similar to AdaBoost but uses gradient descent, often best boosting method\n",
    "- Stacking â†’ can combine different models for potential performance gains\n",
    "\n",
    "âœ… The best model will depend on dataset complexity, but usually **Gradient Boosting or Random Forest** wins."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
