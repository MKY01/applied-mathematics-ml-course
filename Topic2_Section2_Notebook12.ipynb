{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 12 — Model Evaluation & Validation (Exercises)\n",
    "\n",
    "This notebook focuses on evaluating and validating ML models.\n",
    "\n",
    "Topics:\n",
    "- Train/Test Split\n",
    "- Cross-Validation (k-fold, stratified)\n",
    "- Classification & Regression Metrics\n",
    "- Bias-Variance Tradeoff\n",
    "- Learning Curves & Validation Curves\n",
    "\n",
    "Work through the exercises before checking the solutions notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 — Train/Test Split\n",
    "1. Load the **Iris dataset**.\n",
    "2. Perform a train/test split (70/30).\n",
    "3. Fit a Logistic Regression model and report the test accuracy.\n",
    "4. Explain why relying only on train/test split can be misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TODO: Train/test split and evaluate Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 — Cross-Validation\n",
    "1. Use **k-fold cross-validation** (k=5) on the Iris dataset with Logistic Regression.\n",
    "2. Compare the average accuracy from CV to the single train/test split.\n",
    "3. Repeat using **StratifiedKFold** — why is stratification important for imbalanced data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "\n",
    "# TODO: Implement k-fold and stratified cross-validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 — Classification Metrics\n",
    "1. Train a RandomForestClassifier on the **Breast Cancer dataset**.\n",
    "2. Report **Accuracy, Precision, Recall, F1-score, ROC-AUC**.\n",
    "3. Which metric would you prioritize if false negatives are more costly than false positives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# TODO: Train and evaluate classification metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 — Regression Metrics\n",
    "1. Use the **California Housing dataset**.\n",
    "2. Train a RandomForestRegressor.\n",
    "3. Report **MSE, RMSE, MAE, R²**.\n",
    "4. Discuss which metric is most interpretable for business stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Train and evaluate regression metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 — Bias-Variance Tradeoff\n",
    "1. Fit Decision Trees of varying depth on the Iris dataset.\n",
    "2. Record training and test accuracy.\n",
    "3. Plot accuracy vs tree depth.\n",
    "4. Identify underfitting and overfitting regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# TODO: Fit multiple trees with increasing depth and plot train vs test accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6 — Learning Curves\n",
    "1. Generate learning curves for Logistic Regression on the Breast Cancer dataset.\n",
    "2. Plot training score vs validation score across increasing sample sizes.\n",
    "3. What does the gap between curves indicate about bias/variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Implement learning curve plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7 — Validation Curves\n",
    "1. Use the Breast Cancer dataset.\n",
    "2. Generate a validation curve for SVM varying the regularization parameter C.\n",
    "3. Plot training score vs validation score.\n",
    "4. Identify the optimal C value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# TODO: Implement validation curve for SVM with different C values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
